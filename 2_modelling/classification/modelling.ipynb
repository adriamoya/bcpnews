{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: iso-8859-15 -*-\n",
    "\n",
    "# RRN to classify text\n",
    "# Author: adriamoya\n",
    "\n",
    "#%matplotlib inline\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import random as rn\n",
    "import tensorflow as tf\n",
    "\n",
    "# The below is necessary for starting Numpy generated random numbers\n",
    "# in a well-defined initial state.\n",
    "np.random.seed(1337)\n",
    "\n",
    "# The below is necessary for starting core Python generated random numbers\n",
    "# in a well-defined state.\n",
    "rn.seed(12345)\n",
    "\n",
    "# Force TensorFlow to use single thread.\n",
    "# Multiple threads are a potential source of\n",
    "# non-reproducible results.\n",
    "# For further details, see: https://stackoverflow.com/questions/42022950/which-seeds-have-to-be-set-where-to-realize-100-reproducibility-of-training-res\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "\n",
    "from keras import backend as K\n",
    "# The below tf.set_random_seed() will make random number generation\n",
    "# in the TensorFlow backend have a well-defined initial state.\n",
    "# For further details, see: https://www.tensorflow.org/api_docs/python/tf/set_random_seed\n",
    "\n",
    "tf.set_random_seed(1234)\n",
    "\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n",
    "\n",
    "# Rest of code follows ...\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, BatchNormalization, LSTM, Embedding, Reshape, Conv1D, MaxPooling1D\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "#import xgboost as xgb\n",
    "#from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "df = pd.read_csv(\"/home/amoya/.kaggle/competitions/bcpnews/train.csv\")\n",
    "df_test = pd.read_csv(\"/home/amoya/.kaggle/competitions/bcpnews/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ip calculation\n",
    "def ip(y_target, y_pred):\n",
    "    return 100*(2*(metrics.roc_auc_score(y_target, y_pred))-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocessing(df, column=\"text\"):\n",
    "\n",
    "    \"\"\" Preprocessing (lower case, remove urls, punctuations) \"\"\"\n",
    "\n",
    "    print(\"\\nPreprocessing %s ...\" % (column))\n",
    "\n",
    "    # preprocessing steps: lower case, remove urls, punctuations ...\n",
    "    df[column] = df[column].str.lower()\n",
    "    df[column] = df[column].str.replace(r'http[\\w:/\\.]+','') # remove urls\n",
    "    df[column] = df[column].str.replace(r'[^\\.(a-zA-ZÀ-ÿ0-9)\\s]','') #remove everything but characters and punctuation ( [^\\.\\w\\s] )\n",
    "    df[column] = df[column].str.replace(r'(?<=\\d)(\\.)(?=\\d)','') #remove dots in thousands (careful with decimals!)\n",
    "    df[column] = df[column].str.replace(r'\\.\\.+','.') #replace multple periods with a single one\n",
    "    df[column] = df[column].str.replace(r'\\.',' .') #replace multple periods with a single one\n",
    "    df[column] = df[column].str.replace(r'\\(',' ') # replace brackets with white spaces\n",
    "    df[column] = df[column].str.replace(r'\\)',' ') # replace brackets with white spaces\n",
    "    df[column] = df[column].str.replace(r'\\s\\s+',' ') #replace multple white space with a single one\n",
    "    df[column] = df[column].str.strip()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_dictionary(df, min_count_word=5):\n",
    "\n",
    "    \"\"\" Build dictionary and relationships between words and integers \"\"\"\n",
    "\n",
    "    print(\"\\nBuilding dictionary ...\" )\n",
    "\n",
    "    # get all unique words (only consider words that have been used more than 5 times)\n",
    "    all_text = ' '.join(df.text.values)\n",
    "    words = all_text.split()\n",
    "    u_words = Counter(words).most_common()\n",
    "    u_words = [word[0] for word in u_words if word[1]>min_count_word] # we will only consider words that have been used more than 5 times\n",
    "\n",
    "    print('The number of unique words is:', len(u_words) )\n",
    "\n",
    "    # create the dictionary\n",
    "    word2num = dict(zip(u_words,range(len(u_words))))\n",
    "    word2num['<Other>'] = len(u_words)\n",
    "    num2word = dict(zip(word2num.values(), word2num.keys()))\n",
    "\n",
    "    num2word[len(word2num)] = '<PAD>'\n",
    "    word2num['<PAD>'] = len(word2num)\n",
    "\n",
    "    return word2num, num2word, len(u_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word2int(df, n_u_words, column='text', word_threshold=500):\n",
    "\n",
    "    \"\"\" Convert words to integers and prepad sentences \"\"\"\n",
    "\n",
    "    print(\"\\nConverting words to integers and prepadding ...\" )\n",
    "\n",
    "    int_text = [[word2num[word] if word in word2num else n_u_words for word in Text.split()] for Text in df[column].values] # Text.split() python2\n",
    "\n",
    "    print('The number of texts greater than %s in length is: ' % str(word_threshold), np.sum(np.array([len(t)>word_threshold for t in int_text])))\n",
    "    print('The number of texts less than 50 in length is: ', np.sum(np.array([len(t)<50 for t in int_text])) )\n",
    "\n",
    "    for i, t in enumerate(int_text):\n",
    "        if len(t)<word_threshold:\n",
    "            int_text[i] = [word2num['<PAD>']]*(word_threshold-len(t)) + t\n",
    "        elif len(t)>word_threshold:\n",
    "            int_text[i] = t[:word_threshold]\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    return int_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_evaluate_model(X_train, X_valid, y_train, y_valid, params):\n",
    "\n",
    "    \"\"\" Fit and evaluate Many to One RNN \"\"\"\n",
    "\n",
    "    print(\"\\nCreating Sequential RNN: Many to One...\" )\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='loss', patience=2)\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Embedding(len(word2num), params['embedding_size'])) # , batch_size=batch_size\n",
    "    model.add(Conv1D(filters=128, kernel_size=5, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Conv1D(filters=128, kernel_size=5, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(LSTM(100))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid')) # sigmoid\n",
    "    \n",
    "    model.compile(loss=params['loss_func'], optimizer=params['optimizer'], metrics=params['metrics'])\n",
    "    model.summary()\n",
    "\n",
    "    batch_size = params['batch_size']\n",
    "    print(\"\\nFitting the model ...\" )\n",
    "    model.fit(X_train, y_train, batch_size=batch_size, epochs=params['epochs'], callbacks=[early_stopping])\n",
    "    \n",
    "    print(\"\\nPredicting probs on train ...\" )\n",
    "    pred_train = model.predict(X_train)\n",
    "    print(\"\\nAUC: {0:.2f}%\".format(100*metrics.roc_auc_score(y_train, pred_train)), \"| GINI: {0:.2f}%\".format(ip(y_train, pred_train)))\n",
    "\n",
    "    print(\"\\nEvaluating in valid ...\" )\n",
    "    print(model.evaluate(X_valid, y_valid, batch_size=batch_size))\n",
    "    \n",
    "    print(\"\\nPredicting probs on valid ...\" )\n",
    "    pred_valid = model.predict(X_valid)\n",
    "    print(\"\\nAUC: {0:.2f}%\".format(100*metrics.roc_auc_score(y_valid, pred_valid)), \"| GINI: {0:.2f}%\".format(ip(y_valid, pred_valid)))\n",
    "\n",
    "    return model, pred_train, pred_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_test(model, df_test, column):\n",
    "\n",
    "    # words to numbers\n",
    "    int_text = word2int(df_test, n_u_words, column, word_threshold)\n",
    "\n",
    "    X = np.array(int_text)\n",
    "\n",
    "    pred = model.predict(X)\n",
    "\n",
    "    l_pred = []\n",
    "    for item in pred:\n",
    "        l_pred.append(item[0])\n",
    "        \n",
    "    return l_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing steps: lower case, remove urls, punctuations ...\n",
    "\n",
    "# text\n",
    "df = preprocessing(df)\n",
    "df_test = preprocessing(df_test)\n",
    "\n",
    "# title\n",
    "df = preprocessing(df, 'title')\n",
    "df_test = preprocessing(df_test, 'title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build dictionary\n",
    "min_count_word = 4\n",
    "word2num, num2word, n_u_words = build_dictionary(df, min_count_word)\n",
    "\n",
    "# train / valid split\n",
    "print(\"\\nTrain / Valid split ...\" )\n",
    "\n",
    "np.random.seed(0)\n",
    "df['msk'] = np.random.randn(df.shape[0])\n",
    "\n",
    "np.random.seed(0)\n",
    "msk = np.random.rand(len(df)) <= 0.9\n",
    "\n",
    "df_train = df[msk] ; df_train.reset_index(inplace=True); df_train = df_train.drop(['msk', 'index'], axis=1)\n",
    "df_valid = df[~msk]; df_valid.reset_index(inplace=True); df_valid = df_valid.drop(['msk', 'index'], axis=1)\n",
    "\n",
    "print(\"Train shape:\", df_train.shape )\n",
    "print(\"Valid shape:\", df_valid.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_threshold = 500\n",
    "\n",
    "params = {\n",
    "    'loss_func': 'binary_crossentropy', # binary_crossentropy\n",
    "    'optimizer': 'rmsprop', # adam, rmsprop\n",
    "    'metrics': ['accuracy'],\n",
    "    'embedding_size': 100,\n",
    "    'batch_size': 128,\n",
    "    'epochs': 3\n",
    "}\n",
    "\n",
    "# word to integer\n",
    "X_train = np.array(word2int(df_train, n_u_words, 'text', word_threshold))\n",
    "X_valid = np.array(word2int(df_valid, n_u_words, 'text', word_threshold))\n",
    "\n",
    "y_train = df_train['flag'].values\n",
    "y_valid = df_valid['flag'].values\n",
    "\n",
    "model_text, pred_train, pred_valid = fit_evaluate_model(X_train, X_valid, y_train, y_valid, params)\n",
    "\n",
    "print(\"\\nTest results ...\" )\n",
    "test_pred = predict_test(model_text, df_test, 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train['pred_text'] = pred_train\n",
    "df_valid['pred_text'] = pred_valid\n",
    "df_test['pred_text'] = test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_threshold = 15\n",
    "\n",
    "params = {\n",
    "    'loss_func': 'binary_crossentropy', # binary_crossentropy\n",
    "    'optimizer': 'rmsprop', # adam, rmsprop\n",
    "    'metrics': ['accuracy'],\n",
    "    'embedding_size': 100,\n",
    "    'batch_size': 128,\n",
    "    'epochs': 3\n",
    "}\n",
    "\n",
    "# word to integer\n",
    "X_train = np.array(word2int(df_train, n_u_words, 'title', word_threshold))\n",
    "X_valid = np.array(word2int(df_valid, n_u_words, 'title', word_threshold))\n",
    "\n",
    "y_train = df_train['flag'].values\n",
    "y_valid = df_valid['flag'].values\n",
    "\n",
    "model_title, pred_train, pred_valid = fit_evaluate_model(X_train, X_valid, y_train, y_valid, params)\n",
    "\n",
    "print(\"\\nTest results ...\" )\n",
    "test_pred = predict_test(model_title, df_test, 'title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train['pred_title'] = pred_train\n",
    "df_valid['pred_title'] = pred_valid\n",
    "df_test['pred_title'] = test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = df_train[['pred_text', 'pred_title']].values\n",
    "X_valid = df_valid[['pred_text', 'pred_title']].values\n",
    "\n",
    "y_train = df_train['flag'].values\n",
    "y_valid = df_valid['flag'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# xgb sparse matrix\n",
    "xgtrain = xgb.DMatrix(X_train, label= y_train)\n",
    "xgvalid = xgb.DMatrix(X_valid, label= y_valid)\n",
    "\n",
    "clf = XGBClassifier(\n",
    "    booster = 'gbtree',\n",
    "    learning_rate =0.01,\n",
    "    n_estimators=3000, #3000\n",
    "    max_depth=5,\n",
    "    min_child_weight=1,\n",
    "    gamma=0,\n",
    "    subsample=0.7,\n",
    "    colsample_bytree=0.7,\n",
    "    objective= 'binary:logistic',\n",
    "    nthread=4,\n",
    "    scale_pos_weight=1,\n",
    "    seed=99)\n",
    "\n",
    "xgb_param = clf.get_xgb_params()\n",
    "\n",
    "# cross-validation\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "cv_folds = 5\n",
    "early_stopping_rounds = 100\n",
    "\n",
    "print('\\nInitializing cross-validation...')\n",
    "cvresult = xgb.cv(\n",
    "    xgb_param,\n",
    "    xgtrain,\n",
    "    num_boost_round=clf.get_params()['n_estimators'],\n",
    "    nfold=cv_folds,\n",
    "    metrics='auc',\n",
    "    early_stopping_rounds=early_stopping_rounds,\n",
    "    verbose_eval=1)\n",
    "\n",
    "# retrieve parameters\n",
    "print('\\nXGBClassifier parameters')\n",
    "clf.set_params(n_estimators=cvresult.shape[0])\n",
    "\n",
    "# fit the algorithm on the training data\n",
    "print('\\nFit algorithm on train data...')\n",
    "clf.fit(X_train, y_train, eval_metric='auc')\n",
    "\n",
    "# Predict training set\n",
    "# ------------------------------------------------------------------------------\n",
    "print('\\nPredicting on training set...' )\n",
    "dtrain_predictions = clf.predict(X_train)\n",
    "dtrain_predprob = clf.predict_proba(X_train)[:,1]\n",
    "\n",
    "# print model report:\n",
    "print('Model Report' )\n",
    "print('Accuracy : %.4g' % metrics.accuracy_score(y_train , dtrain_predictions) )\n",
    "print('AUC Score (Train): %f' % metrics.roc_auc_score(y_train, dtrain_predprob) )\n",
    "print('IP Score  (Train): %f' % ip(y_train, dtrain_predprob) )\n",
    "\n",
    "# Predict valid set\n",
    "# ------------------------------------------------------------------------------\n",
    "print('\\nPredicting on valid set...' )\n",
    "dvalid_predprob = clf.predict_proba(X_valid)[:,1]\n",
    "\n",
    "# print model report:\n",
    "print('Model Report' )\n",
    "print('AUC Score (Valid): %f' % metrics.roc_auc_score(y_valid, dvalid_predprob) )\n",
    "print('IP Score  (Valid): %f' % ip(y_valid, dvalid_predprob) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(df_test[['pred_text', 'pred_title']])\n",
    "\n",
    "# Predict test set\n",
    "# ------------------------------------------------------------------------------\n",
    "print('\\nPredicting on test set...' )\n",
    "dtest_predprob = clf.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test['pred'] = dtest_predprob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_threshold = 500\n",
    "X_train = np.array(word2int(df_train, n_u_words, 'text', word_threshold))\n",
    "X_valid = np.array(word2int(df_valid, n_u_words, 'text', word_threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_instance = X_valid[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.transpose(X_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train_txt = pd.DataFrame(X_train)\n",
    "df_valid_txt = pd.DataFrame(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lime\n",
    "import lime.lime_tabular\n",
    "\n",
    "# create the lime explainer\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(df_train_text.as_matrix(), feature_names=df_train_txt.columns) # X_train.values, , class_names=(0,1)\n",
    "\n",
    "predict_fn = lambda x: model_text.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exp = explainer.explain_instance(np.reshape(df_valid_txt.loc[1], 500), predict_fn, num_features=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lime\n",
    "# ------------------------------------------------------------------------------\n",
    "print('\\nUsing Lime to explain instances...')\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import re\n",
    "\n",
    "# create the lime explainer\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(df_train[features].as_matrix(), feature_names=features) # X_train.values, , class_names=(0,1)\n",
    "\n",
    "def lime_explain_instance(id):\n",
    "\n",
    "    test_instance_tot = test.loc[test[col_id]==id].head(1)\n",
    "    test_instance = test_instance_tot[features]\n",
    "    test_instance = test_instance.clip(-10000000.0, 10000000.0) # convert int to float instead?\n",
    "    test_instance = test_instance.values[0]\n",
    "\n",
    "    # prediction function: for classifiers, this should be function that takes a numpy array and outputs probability predictions\n",
    "    predict_fn_xgb = lambda x: clf.predict_proba(x).astype(float)\n",
    "\n",
    "    exp = explainer.explain_instance(test_instance, predict_fn_xgb, num_features=200) # test_instance.values\n",
    "    print('Document id     : %d' % (id))\n",
    "    print('Probability (=1):', clf.predict_proba([test_instance])[0,1])\n",
    "    print('True class      : %s' % test_instance_tot[col_target].values[0])\n",
    "\n",
    "    ll = []\n",
    "    for i in range(1, len(exp.as_list()), 1):\n",
    "        id_var = exp.as_map()[1][i][0]\n",
    "        var = features[id_var]\n",
    "        value = test_instance[id_var]\n",
    "        crit = exp.as_list()[i][0]\n",
    "        w = exp.as_list()[i][1]\n",
    "        dd = {\n",
    "            \"variable\": var,\n",
    "            \"value\": value,\n",
    "            \"explanation\": w,\n",
    "            \"criteria\": crit\n",
    "        }\n",
    "        ll.append(dd)\n",
    "\n",
    "    explainer_df = pd.DataFrame(ll)\n",
    "    explainer_df = explainer_df.sort_values('explanation', ascending=False)\n",
    "    explainer_df.head(10)\n",
    "    explainer_df.tail(10)\n",
    "\n",
    "    pyplot.bar(range(len(explainer_df)), explainer_df['explanation'].values)\n",
    "    ind = np.arange(len(explainer_df['variable'].values))    # the x locations for the groups\n",
    "    pyplot.xticks(ind, explainer_df['variable'].values, rotation='vertical')\n",
    "    # pyplot.savefig('3_gbm_raw_feature_importance.png', bbox_inches='tight')\n",
    "    pyplot.show()\n",
    "\n",
    "    return explainer_df\n",
    "\n",
    "# check top 15 of largest estimated probabilities\n",
    "test[['id', 'TARGET', 'predprob']].sort_values('predprob', ascending=False).head(15)\n",
    "\n",
    "\"\"\"\n",
    "2016030520890380\n",
    "2014120519399710\n",
    "2015120012335320\n",
    "2015060519288510\n",
    "2015090014583910\n",
    "2014120013445730\n",
    "\"\"\"\n",
    "explainer_df = lime_explain_instance(2016030520890380)\n",
    "\n",
    "explainer_df.head(10)\n",
    "explainer_df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_submission = df_test[['id', 'pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_time = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print submission_time\n",
    "df_submission.to_csv('../submissions/submission_%s.csv' % submission_time, sep=\",\", na_rep=\"\", mode=\"w\", index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
