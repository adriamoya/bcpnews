{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: iso-8859-15 -*-\n",
    "# https://github.com/keras-team/keras/tree/master/examples\n",
    "#%matplotlib inline\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(2)\n",
    "\n",
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import random as rn\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# Force TensorFlow to use single thread.\n",
    "# Multiple threads are a potential source of\n",
    "# non-reproducible results.\n",
    "# For further details, see: https://stackoverflow.com/questions/42022950/which-seeds-have-to-be-set-where-to-realize-100-reproducibility-of-training-res\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "\n",
    "from keras import backend as K\n",
    "# The below tf.set_random_seed() will make random number generation\n",
    "# in the TensorFlow backend have a well-defined initial state.\n",
    "# For further details, see: https://www.tensorflow.org/api_docs/python/tf/set_random_seed\n",
    "\n",
    "# The below is necessary for starting core Python generated random numbers\n",
    "# in a well-defined state.\n",
    "# rn.seed(12345)\n",
    "\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n",
    "\n",
    "# Rest of code follows ...\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import (Activation, Bidirectional, Dropout, TimeDistributed,\n",
    "                          Flatten, Dense, BatchNormalization, LSTM, Embedding,\n",
    "                          Reshape, Conv1D, MaxPooling1D, AveragePooling1D, GlobalMaxPooling1D)\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import warnings\n",
    "pd.options.mode.chained_assignment = None\n",
    "warnings.filterwarnings(module='sklearn*', action='ignore', category=DeprecationWarning)\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables\n",
    "flag = 'flag'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df = pd.read_csv(\"../../1_construction/3_newspaper_scraper/analyses/cleaned_datasets/train.csv\")\n",
    "df_test  = pd.read_csv(\"../../1_construction/3_newspaper_scraper/analyses/cleaned_datasets/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train / Validation split ...\n",
      "X_train: (13173, 6)\n",
      "X_valid: (1464, 6)\n",
      "y_train: (13173,)\n",
      "y_valid: (1464,)\n"
     ]
    }
   ],
   "source": [
    "# train / validation split\n",
    "print(\"\\nTrain / Validation split ...\")\n",
    "\n",
    "X, y = df[df.columns[~df.columns.str.contains(flag)]].values, df[flag].values\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.1, stratify=y, shuffle=True, random_state=42)\n",
    "\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"X_valid:\", X_valid.shape)\n",
    "print(\"y_train:\", y_train.shape)\n",
    "print(\"y_valid:\", y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df.columns[~df.columns.str.contains(flag)].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(X_train, columns=columns); df_train[flag] = y_train\n",
    "df_valid = pd.DataFrame(X_valid, columns=columns); df_valid[flag] = y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (13173, 7)\n",
      "Valid: (1464, 7)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train:\", df_train.shape)\n",
    "print(\"Valid:\", df_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df, column=\"text\"):\n",
    "    \"\"\"Preprocessing (lower case, remove urls, punctuations).\n",
    "    \n",
    "    Args:\n",
    "        df     : Dataset with articles information (pandas.DataFrame).\n",
    "        column : Name of the column that contains the text of the article. Default is `text`.\n",
    "        \n",
    "    Returns:\n",
    "        df     : Dataset with articles information (pandas.DataFrame).\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    print(\"\\nPreprocessing %s ...\" % (column))\n",
    "\n",
    "    # preprocessing steps: lower case, remove urls, punctuations ...\n",
    "    df[column] = df[column].str.lower()\n",
    "    df[column] = df[column].str.replace(r'http[\\w:/\\.]+','') # remove urls\n",
    "    df[column] = df[column].str.replace(r'[^\\.(a-zA-ZÀ-ÿ0-9)\\s]','') #remove everything but characters and punctuation ( [^\\.\\w\\s] )\n",
    "    df[column] = df[column].str.replace(r'(?<=\\d)(\\.)(?=\\d)','') #remove dots in thousands (careful with decimals!)\n",
    "    df[column] = df[column].str.replace(r'\\.\\.+','.') #replace multple periods with a single one\n",
    "    df[column] = df[column].str.replace(r'\\.',' .') #replace multple periods with a single one\n",
    "    df[column] = df[column].str.replace(r'\\(',' ') # replace brackets with white spaces\n",
    "    df[column] = df[column].str.replace(r'\\)',' ') # replace brackets with white spaces\n",
    "    df[column] = df[column].str.replace(r'\\s\\s+',' ') #replace multple white space with a single one\n",
    "    df[column] = df[column].str.strip()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# preprocessing steps: lower case, remove urls, punctuations ...\n",
    "\n",
    "# text\n",
    "df = preprocessing(df, 'text')\n",
    "df_test = preprocessing(df_test, 'text')\n",
    "\n",
    "# title\n",
    "df = preprocessing(df, 'title')\n",
    "df_test = preprocessing(df_test, 'title')\n",
    "\n",
    "# summary\n",
    "df = preprocessing(df, 'summary')\n",
    "df_test = preprocessing(df_test, 'summary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "def prepare_text_data(train_input, test_input, max_words, max_len):\n",
    "    print('Tokenizing and padding data...')\n",
    "    tok = Tokenizer(num_words=max_words)\n",
    "    tok.fit_on_texts(train_input)\n",
    "    sequences_train = tok.texts_to_sequences(train_input)\n",
    "    sequences_test = tok.texts_to_sequences(test_input)\n",
    "\n",
    "    print('Pad sequences (samples x time)')\n",
    "    train_input_f = sequence.pad_sequences(sequences_train, maxlen=max_len)\n",
    "    test_input_f = sequence.pad_sequences(sequences_test, maxlen=max_len)\n",
    "    return train_input_f, test_input_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_CNN(X_tr, X_te, y_tr, y_te, te_index, oof_train, oof_valid_skf, params):\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.1, patience=1)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(params['max_features'], params['embedding_size'], input_length=params['max_len']))\n",
    "    model.add(Dropout(0.2))\n",
    "    # we add a Convolution1D, which will learn filters\n",
    "    # word group filters of size filter_length:\n",
    "    model.add(Conv1D(filters=params['filters'], kernel_size=params['kernel_size'], padding='valid', activation='relu', strides=1))\n",
    "    # we use max pooling:\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    # We add a vanilla hidden layer:\n",
    "    model.add(Dense(params['hidden_dims']))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "    # We project onto a single unit output layer, and squash it with a sigmoid:\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    model.compile(loss=params['loss_func'],\n",
    "                  optimizer=params['optimizer'],\n",
    "                  metrics=params['metrics'])\n",
    "    \n",
    "    if fold_counter == 0:\n",
    "        model.summary()\n",
    "        \n",
    "    model.fit(X_tr, \n",
    "              y_tr, \n",
    "              batch_size=params['batch_size'],\n",
    "              epochs=params['epochs'],\n",
    "              validation_data=(X_te, y_te),\n",
    "              callbacks=[early_stopping],\n",
    "              verbose=0)\n",
    "\n",
    "    oof_train[te_index] = model.predict(X_te)[:, 0]\n",
    "    oof_valid_skf[params['fold_counter'], :] = model.predict(X_valid)[:, 0]\n",
    "    score = 100*metrics.roc_auc_score(y_valid, oof_valid_skf[params['fold_counter'], :])\n",
    "    print('fold %d: [%.4f]' % (params['fold_counter']+1, score))  \n",
    "    \n",
    "    model.save('models/CNN_%s_%s.h5' % (params['feature'], params['fold_counter']))\n",
    "\n",
    "    return oof_train, oof_valid_skf\n",
    "\n",
    "\n",
    "def model_LSTM(X_tr, X_te, y_tr, y_te, te_index, oof_train, oof_valid_skf, params):\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.1, patience=1)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Embedding(params['max_features'], params['embedding_size'], input_length=params['max_len']))\n",
    "    model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss=params['loss_func'],\n",
    "                  optimizer=params['optimizer'],\n",
    "                  metrics=params['metrics'])\n",
    "    \n",
    "    if fold_counter == 0:\n",
    "        model.summary()\n",
    "        \n",
    "    model.fit(X_tr, \n",
    "              y_tr, \n",
    "              batch_size=params['batch_size'],\n",
    "              epochs=params['epochs'],\n",
    "              validation_data=(X_te, y_te),\n",
    "              callbacks=[early_stopping],\n",
    "              verbose=0)\n",
    "    \n",
    "    oof_train[te_index] = model.predict(X_te)[:, 0]\n",
    "    oof_valid_skf[params['fold_counter'], :] = model.predict(X_valid)[:, 0]\n",
    "    score = 100*metrics.roc_auc_score(y_valid, oof_valid_skf[params['fold_counter'], :])\n",
    "    print('fold %d: [%.4f]' % (params['fold_counter']+1, score))  \n",
    "    \n",
    "    model.save('models/LSTM_%s_%s.h5' % (params['feature'], params['fold_counter']))\n",
    "\n",
    "    return oof_train, oof_valid_skf\n",
    "\n",
    "\n",
    "def model_BiLSTM(X_tr, X_te, y_tr, y_te, te_index, oof_train, oof_valid_skf, params):\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.1, patience=1)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Embedding(params['max_features'], params['embedding_size'], input_length=params['max_len']))\n",
    "    model.add(Bidirectional(LSTM(64)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss=params['loss_func'],\n",
    "                  optimizer=params['optimizer'],\n",
    "                  metrics=params['metrics'])\n",
    "    \n",
    "    if fold_counter == 0:\n",
    "        model.summary()\n",
    "        \n",
    "    model.fit(X_tr, \n",
    "              y_tr, \n",
    "              batch_size=params['batch_size'],\n",
    "              epochs=params['epochs'],\n",
    "              validation_data=(X_te, y_te),\n",
    "              callbacks=[early_stopping],\n",
    "              verbose=0)\n",
    "    \n",
    "    oof_train[te_index] = model.predict(X_te)[:, 0]\n",
    "    oof_valid_skf[params['fold_counter'], :] = model.predict(X_valid)[:, 0]\n",
    "    score = 100*metrics.roc_auc_score(y_valid, oof_valid_skf[params['fold_counter'], :])\n",
    "    print('fold %d: [%.4f]' % (params['fold_counter']+1, score))\n",
    "    \n",
    "    model.save('models/BiLSTM_%s_%s.h5' % (params['feature'], params['fold_counter']))\n",
    "\n",
    "    return oof_train, oof_valid_skf\n",
    "\n",
    "\n",
    "def model_CNNLSTM(X_tr, X_te, y_tr, y_te, te_index, oof_train, oof_valid_skf, params):\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.1, patience=1)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Embedding(params['max_features'], params['embedding_size'], input_length=params['max_len']))\n",
    "    model.add(Conv1D(filters=params['filters'], kernel_size=params['kernel_size'], padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=params['pool_size']))\n",
    "    model.add(Conv1D(filters=params['filters'], kernel_size=params['kernel_size'], padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=params['pool_size']))\n",
    "    model.add(LSTM(100))\n",
    "    model.add(Dense(1, activation='sigmoid')) # sigmoid\n",
    "    \n",
    "    model.compile(loss=params['loss_func'],\n",
    "                  optimizer=params['optimizer'],\n",
    "                  metrics=params['metrics'])\n",
    "    \n",
    "    if fold_counter == 0:\n",
    "        model.summary()\n",
    "\n",
    "    model.fit(X_tr, \n",
    "              y_tr, \n",
    "              batch_size=params['batch_size'],\n",
    "              epochs=params['epochs'],\n",
    "              validation_data=(X_te, y_te),\n",
    "              callbacks=[early_stopping],\n",
    "              verbose=0)\n",
    "    \n",
    "    oof_train[te_index] = model.predict(X_te)[:, 0]\n",
    "    oof_valid_skf[params['fold_counter'], :] = model.predict(X_valid)[:, 0]\n",
    "    score = 100*metrics.roc_auc_score(y_valid, oof_valid_skf[params['fold_counter'], :])\n",
    "    print('fold %d: [%.4f]' % (params['fold_counter']+1, score))\n",
    "    \n",
    "    model.save('models/CNNLSTM_%s_%s.h5' % (params['feature'], params['fold_counter']))\n",
    "\n",
    "    return oof_train, oof_valid_skf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing and padding data...\n",
      "Pad sequences (samples x time)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Model 1 of 12. CNN architecture using feature 'title'\n",
      "--------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 20, 100)           1000000   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 20, 100)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 18, 250)           75250     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 250)               62750     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 251       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,138,251\n",
      "Trainable params: 1,138,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "fold 1: [94.1389]\n",
      "fold 2: [93.6430]\n",
      "fold 3: [94.0519]\n",
      "fold 4: [94.1104]\n",
      "\n",
      "Averaging scores in out of fold valid dataset...\n",
      "valid:  [94.8745]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Model 2 of 12. LSTM architecture using feature 'title'\n",
      "--------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 20, 100)           1000000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               117248    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,117,377\n",
      "Trainable params: 1,117,377\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "fold 1: [94.2053]\n",
      "fold 2: [93.9098]\n",
      "fold 3: [94.1039]\n",
      "fold 4: [93.9272]\n",
      "\n",
      "Averaging scores in out of fold valid dataset...\n",
      "valid:  [94.5574]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Model 3 of 12. BiLSTM architecture using feature 'title'\n",
      "--------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 20, 100)           1000000   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 128)               84480     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,084,609\n",
      "Trainable params: 1,084,609\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "fold 1: [94.2301]\n",
      "fold 2: [93.8193]\n",
      "fold 3: [93.6891]\n",
      "fold 4: [94.0484]\n",
      "\n",
      "Averaging scores in out of fold valid dataset...\n",
      "valid:  [94.5410]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Model 4 of 12. CNNLSTM architecture using feature 'title'\n",
      "--------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_13 (Embedding)     (None, 20, 100)           1000000   \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 20, 250)           75250     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 10, 250)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 10, 250)           187750    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 5, 250)            0         \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 100)               140400    \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 1,403,501\n",
      "Trainable params: 1,403,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "fold 1: [94.0605]\n",
      "fold 2: [93.7886]\n",
      "fold 3: [93.1407]\n",
      "fold 4: [93.9232]\n",
      "\n",
      "Averaging scores in out of fold valid dataset...\n",
      "valid:  [94.4828]\n",
      "Tokenizing and padding data...\n",
      "Pad sequences (samples x time)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Model 5 of 12. CNN architecture using feature 'summary'\n",
      "--------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_17 (Embedding)     (None, 250, 100)          4000000   \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 250, 100)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 248, 250)          75250     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_5 (Glob (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 250)               62750     \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1)                 251       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 4,138,251\n",
      "Trainable params: 4,138,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "fold 1: [92.4580]\n",
      "fold 2: [93.3288]\n",
      "fold 3: [92.8810]\n",
      "fold 4: [93.2063]\n",
      "\n",
      "Averaging scores in out of fold valid dataset...\n",
      "valid:  [94.1755]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Model 6 of 12. LSTM architecture using feature 'summary'\n",
      "--------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_21 (Embedding)     (None, 250, 100)          4000000   \n",
      "_________________________________________________________________\n",
      "lstm_13 (LSTM)               (None, 128)               117248    \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 4,117,377\n",
      "Trainable params: 4,117,377\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1: [91.3869]\n",
      "fold 2: [91.0723]\n",
      "fold 3: [91.5570]\n",
      "fold 4: [88.8381]\n",
      "\n",
      "Averaging scores in out of fold valid dataset...\n",
      "valid:  [92.2579]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Model 7 of 12. BiLSTM architecture using feature 'summary'\n",
      "--------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_25 (Embedding)     (None, 250, 100)          4000000   \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, 128)               84480     \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 4,084,609\n",
      "Trainable params: 4,084,609\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "fold 1: [91.5867]\n",
      "fold 2: [92.3055]\n",
      "fold 3: [92.8044]\n",
      "fold 4: [92.2919]\n",
      "\n",
      "Averaging scores in out of fold valid dataset...\n",
      "valid:  [93.3250]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Model 8 of 12. CNNLSTM architecture using feature 'summary'\n",
      "--------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_29 (Embedding)     (None, 250, 100)          4000000   \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 250, 250)          75250     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 125, 250)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 125, 250)          187750    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 62, 250)           0         \n",
      "_________________________________________________________________\n",
      "lstm_21 (LSTM)               (None, 100)               140400    \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 4,403,501\n",
      "Trainable params: 4,403,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "fold 1: [92.2230]\n",
      "fold 2: [91.2865]\n",
      "fold 3: [91.4985]\n",
      "fold 4: [92.0638]\n",
      "\n",
      "Averaging scores in out of fold valid dataset...\n",
      "valid:  [92.8597]\n",
      "Tokenizing and padding data...\n",
      "Pad sequences (samples x time)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Model 9 of 12. CNN architecture using feature 'text'\n",
      "--------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_33 (Embedding)     (None, 500, 100)          4000000   \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 500, 100)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 498, 250)          75250     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_9 (Glob (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 250)               62750     \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 1)                 251       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 4,138,251\n",
      "Trainable params: 4,138,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "fold 1: [94.3909]\n",
      "fold 2: [94.7536]\n",
      "fold 3: [94.6136]\n",
      "fold 4: [95.1114]\n",
      "\n",
      "Averaging scores in out of fold valid dataset...\n",
      "valid:  [95.2632]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Model 10 of 12. LSTM architecture using feature 'text'\n",
      "--------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_37 (Embedding)     (None, 500, 100)          4000000   \n",
      "_________________________________________________________________\n",
      "lstm_25 (LSTM)               (None, 128)               117248    \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 4,117,377\n",
      "Trainable params: 4,117,377\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "fold 1: [86.8477]\n",
      "fold 2: [88.7288]\n",
      "fold 3: [90.0290]\n",
      "fold 4: [87.7482]\n",
      "\n",
      "Averaging scores in out of fold valid dataset...\n",
      "valid:  [90.6042]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Model 11 of 12. BiLSTM architecture using feature 'text'\n",
      "--------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_41 (Embedding)     (None, 500, 100)          4000000   \n",
      "_________________________________________________________________\n",
      "bidirectional_9 (Bidirection (None, 128)               84480     \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 4,084,609\n",
      "Trainable params: 4,084,609\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "fold 1: [89.6704]\n",
      "fold 2: [90.7160]\n",
      "fold 3: [92.5063]\n",
      "fold 4: [76.0643]\n",
      "\n",
      "Averaging scores in out of fold valid dataset...\n",
      "valid:  [93.6045]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Model 12 of 12. CNNLSTM architecture using feature 'text'\n",
      "--------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_45 (Embedding)     (None, 500, 100)          4000000   \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 500, 250)          75250     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 250, 250)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 250, 250)          187750    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 125, 250)          0         \n",
      "_________________________________________________________________\n",
      "lstm_33 (LSTM)               (None, 100)               140400    \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 4,403,501\n",
      "Trainable params: 4,403,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1: [89.2585]\n",
      "fold 2: [90.8457]\n",
      "fold 3: [90.7415]\n",
      "fold 4: [92.2874]\n",
      "\n",
      "Averaging scores in out of fold valid dataset...\n",
      "valid:  [92.4560]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "NFOLDS = 4\n",
    "\n",
    "features = [{\"name\": \"title\", \"max_len\": 20, \"max_features\": 10000},\n",
    "            {\"name\": \"summary\", \"max_len\": 250, \"max_features\": 40000},\n",
    "            {\"name\": \"text\", \"max_len\": 500, \"max_features\": 40000}]\n",
    "            \n",
    "models = ['CNN', 'LSTM', 'BiLSTM', 'CNNLSTM']\n",
    "\n",
    "params = {\n",
    "    'loss_func': 'binary_crossentropy', # binary_crossentropy\n",
    "    'optimizer': 'adam', # adam, rmsprop\n",
    "    'metrics': ['accuracy'],\n",
    "    'embedding_size': 100,\n",
    "    'batch_size': 128,\n",
    "    'epochs': 3,\n",
    "    'filters': 250, # 128\n",
    "    'kernel_size': 3,\n",
    "    'hidden_dims': 250,\n",
    "    'pool_size': 2\n",
    "}\n",
    "\n",
    "train_level_2 = np.zeros((df_train.shape[0], len(models) * len(features)))\n",
    "valid_level_2 = np.zeros((df_valid.shape[0], len(models) * len(features)))\n",
    "\n",
    "for feature_counter, feature in enumerate(features):\n",
    "    \n",
    "    params['max_len'] = feature['max_len']\n",
    "    params['max_features'] = feature['max_features']\n",
    "    params['feature'] = feature['name']\n",
    "\n",
    "    # word to integer\n",
    "    X_train, X_valid =  prepare_text_data(df_train[feature['name']].values,\n",
    "                                          df_valid[feature['name']].values,\n",
    "                                          params['max_features'],\n",
    "                                          params['max_len'])\n",
    "\n",
    "    ntrain = X_train.shape[0]\n",
    "    nvalid = X_valid.shape[0]\n",
    "    \n",
    "    for model_counter, model in enumerate(models):\n",
    "        \n",
    "        idx = feature_counter*len(models) + model_counter + 1\n",
    "\n",
    "        print(\"\")\n",
    "        print(\"-\"*80)\n",
    "        print(\"Model {} of {}. {} architecture using feature '{}'\".format(idx, len(models)*len(features), model, feature['name']))\n",
    "        print(\"-\"*80)\n",
    "\n",
    "        oof_train = np.zeros((ntrain,))\n",
    "        oof_valid = np.zeros((nvalid,))\n",
    "        oof_valid_skf = np.empty((NFOLDS, nvalid))\n",
    "\n",
    "        kf = StratifiedKFold(n_splits=NFOLDS, shuffle=False, random_state=0)\n",
    "\n",
    "        for fold_counter, (tr_index, te_index) in enumerate(kf.split(X_train, y_train)):\n",
    "            \n",
    "            params['fold_counter'] = fold_counter\n",
    "\n",
    "            # Split data and target\n",
    "            X_tr = X_train[tr_index]\n",
    "            y_tr = y_train[tr_index]\n",
    "            X_te = X_train[te_index]\n",
    "            y_te = y_train[te_index]\n",
    "\n",
    "            if model == \"CNN\":\n",
    "                oof_train, oof_valid_skf = model_CNN(X_tr, X_te, y_tr, y_te, te_index, oof_train, oof_valid_skf, params)\n",
    "            elif model == \"LSTM\":\n",
    "                oof_train, oof_valid_skf = model_LSTM(X_tr, X_te, y_tr, y_te, te_index, oof_train, oof_valid_skf, params)\n",
    "            elif model == \"BiLSTM\":\n",
    "                oof_train, oof_valid_skf = model_BiLSTM(X_tr, X_te, y_tr, y_te, te_index, oof_train, oof_valid_skf, params)\n",
    "            elif model == \"CNNLSTM\":\n",
    "                oof_train, oof_valid_skf = model_CNNLSTM(X_tr, X_te, y_tr, y_te, te_index, oof_train, oof_valid_skf, params)                \n",
    "\n",
    "        train_level_2[:, idx-1] = oof_train[:]\n",
    "        \n",
    "        print(\"\\nAveraging scores in out of fold valid dataset...\")\n",
    "        oof_valid[:] = oof_valid_skf.mean(axis=0)\n",
    "        valid_level_2[:, idx-1] = oof_valid[:]\n",
    "        score = 100*metrics.roc_auc_score(y_valid, oof_valid[:])\n",
    "        print('valid:  [%.4f]' % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "NFOLDS = 4\n",
    "\n",
    "features = [{\"name\": \"title\", \"max_len\": 20, \"max_features\": 10000},\n",
    "            {\"name\": \"summary\", \"max_len\": 250, \"max_features\": 40000},\n",
    "            {\"name\": \"text\", \"max_len\": 500, \"max_features\": 40000}]  # , {\"feature\": \"summary\", \"word_threshold\": 250}\n",
    "models = ['CNN', 'LSTM', 'BiLSTM', 'CNNLSTM']\n",
    "\n",
    "params = {\n",
    "    'loss_func': 'binary_crossentropy', # binary_crossentropy\n",
    "    'optimizer': 'adam', # adam, rmsprop\n",
    "    'metrics': ['accuracy'],\n",
    "    'embedding_size': 100,\n",
    "    'batch_size': 128,\n",
    "    'epochs': 3,\n",
    "    'filters': 250, # 128\n",
    "    'kernel_size': 3,\n",
    "    'hidden_dims': 250,\n",
    "    'pool_size': 2\n",
    "}\n",
    "\n",
    "train_level_2 = np.zeros((df_train.shape[0], len(models) * len(features)))\n",
    "valid_level_2 = np.zeros((df_valid.shape[0], len(models) * len(features)))\n",
    "\n",
    "for feature_counter, feature in enumerate(features):\n",
    "    \n",
    "    params['max_len'] = feature['max_len']\n",
    "    params['max_features'] = feature['max_features']\n",
    "    params['feature'] = feature['name']\n",
    "\n",
    "    # word to integer\n",
    "    X_train, X_valid =  prepare_text_data(df_train[feature['name']].values,\n",
    "                                          df_valid[feature['name']].values,\n",
    "                                          params['max_features'],\n",
    "                                          params['max_len'])\n",
    "\n",
    "    ntrain = X_train.shape[0]\n",
    "    nvalid = X_valid.shape[0]\n",
    "    \n",
    "    for model_counter, model_name in enumerate(models):\n",
    "        \n",
    "        idx = feature_counter*len(models) + model_counter + 1\n",
    "\n",
    "        print(\"\")\n",
    "        print(\"-\"*80)\n",
    "        print(\"Model {} of {}. {} architecture using feature '{}'\".format(idx, len(models)*len(features), model_name, feature['name']))\n",
    "        print(\"-\"*80)\n",
    "\n",
    "        oof_train = np.zeros((ntrain,))\n",
    "        oof_valid = np.zeros((nvalid,))\n",
    "        oof_valid_skf = np.empty((NFOLDS, nvalid))\n",
    "\n",
    "        kf = StratifiedKFold(n_splits=NFOLDS, shuffle=False, random_state=0)\n",
    "\n",
    "        for fold_counter, (tr_index, te_index) in enumerate(kf.split(X_train, y_train)):\n",
    "            \n",
    "            params['fold_counter'] = fold_counter\n",
    "\n",
    "            # Split data and target\n",
    "            X_tr = X_train[tr_index]\n",
    "            y_tr = y_train[tr_index]\n",
    "            X_te = X_train[te_index]\n",
    "            y_te = y_train[te_index]\n",
    "\n",
    "            model = load_model('models/%s_%s_%s.h5' % (model_name, feature['name'], fold_counter))\n",
    "\n",
    "            oof_train[te_index] = model.predict(X_te)[:, 0]\n",
    "            oof_valid_skf[params['fold_counter'], :] = model.predict(X_valid)[:, 0]\n",
    "            score = 100*metrics.roc_auc_score(y_valid, oof_valid_skf[params['fold_counter'], :])\n",
    "            print('fold %d: [%.4f]' % (params['fold_counter']+1, score))             \n",
    "\n",
    "        train_level_2[:, idx-1] = oof_train[:]\n",
    "        \n",
    "        print(\"\\nAveraging scores in out of fold valid dataset...\")\n",
    "        oof_valid[:] = oof_valid_skf.mean(axis=0)\n",
    "        valid_level_2[:, idx-1] = oof_valid[:]\n",
    "        score = 100*metrics.roc_auc_score(y_valid, oof_valid[:])\n",
    "        print('valid:  [%.4f]' % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomized search...\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:  6.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV train with XGBoost AUC: 0.9764922336309555\n",
      "CV valid with XGBoost AUC: 0.9637788598857505\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# saving the model\n",
    "params = {\n",
    "        'min_child_weight': [1, 3, 5],\n",
    "        'gamma': [0.5, 1, 1.5, 2],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 4, 5],\n",
    "        'learning_rate': [0.1, 0.01, 0.005]\n",
    "        }\n",
    "\n",
    "xgb = XGBClassifier(learning_rate=0.001, n_estimators=10000,\n",
    "                    objective='binary:logistic', silent=True)\n",
    "PARAM_COMB = 5\n",
    "\n",
    "skf = StratifiedKFold(n_splits=NFOLDS, shuffle = True, random_state = 1001)\n",
    "\n",
    "print(\"Randomized search...\")\n",
    "random_search = RandomizedSearchCV(xgb,\n",
    "                                   param_distributions=params,\n",
    "                                   n_iter=PARAM_COMB,\n",
    "                                   scoring='roc_auc',\n",
    "                                   n_jobs=-1,\n",
    "                                   cv=skf.split(train_level_2, y_train),\n",
    "                                   verbose=1,  # 2\n",
    "                                   random_state=1001 )\n",
    "\n",
    "random_search.fit(train_level_2, y_train)\n",
    "\n",
    "pickle.dump(random_search.best_estimator_, open('models/xgboost_level_2.dat', \"wb\"))\n",
    "\n",
    "pred_train = random_search.predict_proba(train_level_2)[:, 1]\n",
    "cv_train_auc = roc_auc_score(y_train, pred_train)\n",
    "print('CV train with XGBoost AUC: {}'.format(cv_train_auc))\n",
    "\n",
    "pred_valid = random_search.predict_proba(valid_level_2)[:, 1]\n",
    "cv_valid_auc = roc_auc_score(y_valid, pred_valid)\n",
    "print('CV valid with XGBoost AUC: {}'.format(cv_valid_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV train with XGBoost AUC: [0.9765]\n",
      "CV valid with XGBoost AUC: [0.9638]\n"
     ]
    }
   ],
   "source": [
    "# loading the model\n",
    "random_search = pickle.load(open('models/xgboost_level_2.dat', \"rb\"))\n",
    "\n",
    "pred_train = random_search.predict_proba(train_level_2)[:, 1]\n",
    "cv_train_auc = roc_auc_score(y_train, pred_train)\n",
    "print('CV train with XGBoost AUC: [%.4f]' % cv_train_auc)\n",
    "\n",
    "pred_valid = random_search.predict_proba(valid_level_2)[:, 1]\n",
    "cv_valid_auc = roc_auc_score(y_valid, pred_valid)\n",
    "print('CV valid with XGBoost AUC: [%.4f]' % cv_valid_auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
